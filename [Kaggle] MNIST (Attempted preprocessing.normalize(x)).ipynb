{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loaded mnist data!\n",
      "test_data (10000, 784)\n",
      "training_data (60000, 784)\n",
      "training_labels (60000, 1)\n",
      "\n",
      "loaded spam data!\n",
      "test_data (5857, 154)\n",
      "training_data (5172, 154)\n",
      "training_labels (5172, 1)\n",
      "\n",
      "loaded cifar10 data!\n",
      "test_data (10000, 3072)\n",
      "training_data (50000, 3072)\n",
      "training_labels (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Prerequisite\n",
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Python 3 not detected.\")\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import svm\n",
    "from scipy import io\n",
    "\n",
    "for data_name in [\"mnist\", \"spam\", \"cifar10\"]:\n",
    "    data = io.loadmat(\"/Users/jinhan/Downloads/hw1/data/%s_data.mat\" % data_name)\n",
    "    print(\"\\nloaded %s data!\" % data_name)\n",
    "    fields = \"test_data\", \"training_data\", \"training_labels\"\n",
    "    for field in fields:\n",
    "        print(field, data[field].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Data Partitioning\n",
    "import random\n",
    "# mnist training and validation set\n",
    "mnist_data = io.loadmat(\"/Users/jinhan/Downloads/hw1/data/mnist_data.mat\")\n",
    "\n",
    "# zip training data and training labels\n",
    "mapped = list(zip(mnist_data['training_data'],mnist_data['training_labels']))\n",
    "\n",
    "# shuffle the data with corresponding label\n",
    "shuffled_mapped_array = random.sample(mapped, len(mapped))\n",
    "\n",
    "# split validation set and the remaining training set\n",
    "validation_set = shuffled_mapped_array[:10000]\n",
    "remaining_set = shuffled_mapped_array[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for 100 examples is  0.6414\n",
      "Training accuracy for 100 examples is  0.86\n",
      "Validation accuracy for 200 examples is  0.8237\n",
      "Training accuracy for 200 examples is  0.97\n",
      "Validation accuracy for 500 examples is  0.8666\n",
      "Training accuracy for 500 examples is  0.944\n",
      "Validation accuracy for 1000 examples is  0.8955\n",
      "Training accuracy for 1000 examples is  0.958\n",
      "Validation accuracy for 2000 examples is  0.909\n",
      "Training accuracy for 2000 examples is  0.9455\n",
      "Validation accuracy for 5000 examples is  0.9195\n",
      "Training accuracy for 5000 examples is  0.941\n",
      "Validation accuracy for 10000 examples is  0.9277\n",
      "Training accuracy for 10000 examples is  0.9447\n",
      "Validation accuracy for 30000 examples is  0.9277\n",
      "Training accuracy for 30000 examples is  0.9457\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Question 2: SVM\n",
    "# 2a)\n",
    "\n",
    "# Try using preprocessing.normalize(x) function\n",
    "\n",
    "# Unzip the features and labels\n",
    "res = list(zip(*remaining_set)) \n",
    "mnist_tr_features = preprocessing.normalize(res[0])\n",
    "mnist_tr_labels = res[1]\n",
    "\n",
    "unzip_mnist_val = list(zip(*validation_set))\n",
    "mnist_val_features = preprocessing.normalize(unzip_mnist_val[0])\n",
    "mnist_val_labels = unzip_mnist_val[1]\n",
    "\n",
    "# Different num examples of training sets (X_train)\n",
    "training_100 = mnist_tr_features[:100]\n",
    "training_200 = mnist_tr_features[100:300]\n",
    "training_500 = mnist_tr_features[300:800]\n",
    "training_1000 = mnist_tr_features[800:1800]\n",
    "training_2000 = mnist_tr_features[1800:3800]\n",
    "training_5000 = mnist_tr_features[3800:8800]\n",
    "training_10000 = mnist_tr_features[8800:18800]\n",
    "training_30000 = mnist_tr_features[18800:38800]\n",
    "\n",
    "# Y_train\n",
    "y_train_100 = mnist_tr_labels[:100]\n",
    "y_train_200 = mnist_tr_labels[100:300]\n",
    "y_train_500 = mnist_tr_labels[300:800]\n",
    "y_train_1000 = mnist_tr_labels[800:1800]\n",
    "y_train_2000 = mnist_tr_labels[1800:3800]\n",
    "y_train_5000 = mnist_tr_labels[3800:8800]\n",
    "y_train_10000 = mnist_tr_labels[8800:18800]\n",
    "y_train_30000 = mnist_tr_labels[18800:38800]\n",
    "\n",
    "# X_test \n",
    "\n",
    "x_test = mnist_val_features\n",
    "\n",
    "# Y_test\n",
    "\n",
    "y_test = mnist_val_labels \n",
    "\n",
    "# Create svm Classifier for each num example\n",
    "clf_100 = svm.SVC(kernel='linear') # Linear Kernel\n",
    "clf_200 = svm.SVC(kernel='linear')\n",
    "clf_500 = svm.SVC(kernel='linear')\n",
    "clf_1000 = svm.SVC(kernel='linear')\n",
    "clf_2000 = svm.SVC(kernel='linear')\n",
    "clf_5000 = svm.SVC(kernel='linear')\n",
    "clf_10000 = svm.SVC(kernel='linear')\n",
    "clf_30000 = svm.SVC(kernel = 'linear')\n",
    "\n",
    "# Fit the model to each respective data\n",
    "clf_100.fit(training_100, np.ravel(y_train_100))\n",
    "clf_200.fit(training_200, np.ravel(y_train_200))\n",
    "clf_500.fit(training_500, np.ravel(y_train_500))\n",
    "clf_1000.fit(training_1000, np.ravel(y_train_1000))\n",
    "clf_2000.fit(training_2000, np.ravel(y_train_2000))\n",
    "clf_5000.fit(training_5000, np.ravel(y_train_5000))\n",
    "clf_10000.fit(training_10000, np.ravel(y_train_10000))\n",
    "clf_30000.fit(training_30000, np.ravel(y_train_30000))\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred_100 = clf_100.predict(x_test) \n",
    "y_pred_200 = clf_200.predict(x_test)\n",
    "y_pred_500 = clf_500.predict(x_test)\n",
    "y_pred_1000 = clf_1000.predict(x_test)\n",
    "y_pred_2000 = clf_2000.predict(x_test)\n",
    "y_pred_5000 = clf_5000.predict(x_test)\n",
    "y_pred_10000 = clf_10000.predict(x_test)\n",
    "y_pred_30000 = clf_10000.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Validation accuracy for 100 examples is \", accuracy_score(y_test,y_pred_100)) # Validation accuracy \n",
    "print(\"Training accuracy for 100 examples is \", accuracy_score(y_train_100,clf_100.predict(training_100))) # Training accuracy \n",
    "\n",
    "print(\"Validation accuracy for 200 examples is \", accuracy_score(y_test,y_pred_200)) # Validation accuracy \n",
    "print(\"Training accuracy for 200 examples is \", accuracy_score(y_train_200,clf_200.predict(training_200))) # Training accuracy \n",
    "\n",
    "print(\"Validation accuracy for 500 examples is \", accuracy_score(y_test,y_pred_500)) # Validation accuracy \n",
    "print(\"Training accuracy for 500 examples is \", accuracy_score(y_train_500,clf_500.predict(training_500))) # Training accuracy \n",
    "\n",
    "print(\"Validation accuracy for 1000 examples is \", accuracy_score(y_test,y_pred_1000)) # Validation accuracy \n",
    "print(\"Training accuracy for 1000 examples is \", accuracy_score(y_train_1000,clf_1000.predict(training_1000))) # Training accuracy \n",
    "\n",
    "print(\"Validation accuracy for 2000 examples is \", accuracy_score(y_test,y_pred_2000)) # Validation accuracy \n",
    "print(\"Training accuracy for 2000 examples is \", accuracy_score(y_train_2000,clf_2000.predict(training_2000))) # Training accuracy \n",
    "\n",
    "print(\"Validation accuracy for 5000 examples is \", accuracy_score(y_test,y_pred_5000)) # Validation accuracy \n",
    "print(\"Training accuracy for 5000 examples is \", accuracy_score(y_train_5000,clf_5000.predict(training_5000))) # Training accuracy \n",
    "\n",
    "print(\"Validation accuracy for 10000 examples is \", accuracy_score(y_test,y_pred_10000)) # Validation accuracy \n",
    "print(\"Training accuracy for 10000 examples is \", accuracy_score(y_train_10000,clf_10000.predict(training_10000))) # Training accuracy \n",
    "\n",
    "print(\"Validation accuracy for 30000 examples is \", accuracy_score(y_test,y_pred_30000)) # Validation accuracy \n",
    "print(\"Training accuracy for 30000 examples is \", accuracy_score(y_train_30000,clf_30000.predict(training_30000))) # Training accuracy \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
